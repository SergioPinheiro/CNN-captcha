{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12556 images belonging to 28 classes.\n",
      "Found 1710 images belonging to 28 classes.\n",
      "Found 3515 images belonging to 28 classes.\n"
     ]
    }
   ],
   "source": [
    "file = 'dataset_1'\n",
    "\n",
    "train_datagen = K.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "validation_datagen = K.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "test_datagen = K.preprocessing.image.ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        os.path.join(file, 'train'),\n",
    "        target_size=(50, 50),\n",
    "        batch_size=1,\n",
    "        color_mode='grayscale',\n",
    "        class_mode='categorical',\n",
    "        )\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        os.path.join(file, 'validation'),\n",
    "        target_size=(50, 50),\n",
    "        batch_size=1,\n",
    "        color_mode='grayscale',\n",
    "        class_mode=\"categorical\",\n",
    "        )\n",
    "\n",
    "test_generator = validation_datagen.flow_from_directory(\n",
    "        os.path.join(file, 'test'),\n",
    "        target_size=(50, 50),\n",
    "        batch_size=1,\n",
    "        color_mode='grayscale',\n",
    "        class_mode=\"categorical\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = K.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                              min_delta=0,\n",
    "                              patience=3,\n",
    "                              verbose=0, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetRelu:\n",
    "    @staticmethod\n",
    "    def build(input_shape, classes):\n",
    "        model = Sequential()\n",
    "        \n",
    "        model.add(Conv2D(7, kernel_size=3, strides=2, input_shape=input_shape))\n",
    "        model.add(Activation('selu'))\n",
    "#         model.add(LeakyReLU())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "        model.add(Conv2D(14, kernel_size=3, strides=2, border_mode=\"same\"))\n",
    "#         model.add(Activation('selu'))\n",
    "        model.add(LeakyReLU())\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        \n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation('selu'))\n",
    "#         model.add(LeakyReLU())\n",
    "        \n",
    "        model.add(Dense(classes))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \n",
    "def f_score_calc(model):\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    y_pred = []\n",
    "    for i in range(len(test_generator)):\n",
    "        X_ex, y_ex = test_generator.next()\n",
    "        X_test.append(X_ex)\n",
    "        y_test.append(y_ex.argmax(axis=-1))\n",
    "        y_pred.append(model.predict(X_ex).argmax(axis=-1))\n",
    "\n",
    "    val_f1_score = f1_score(y_test, y_pred, average='micro')\n",
    "    return val_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (50, 50, 1)\n",
    "NB_EPOCH = 50\n",
    "BATCH_SIZE = 32\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = Adam()\n",
    "CLASSES = 28\n",
    "STEPS = (int)(train_generator.n/BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.backend.get_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(14, kernel_size=3, strides=2, padding=\"same\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 24, 24, 7)         70        \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 24, 24, 7)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 12, 12, 7)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 6, 6, 14)          896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_25 (LeakyReLU)   (None, 6, 6, 14)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 3, 3, 14)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 126)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 500)               63500     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 28)                14028     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 28)                0         \n",
      "=================================================================\n",
      "Total params: 78,494\n",
      "Trainable params: 78,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "392/392 [==============================] - 6s 16ms/step - loss: 15.7264 - acc: 0.0230 - val_loss: 15.3640 - val_acc: 0.0468\n",
      "Epoch 2/50\n",
      "392/392 [==============================] - 5s 13ms/step - loss: 15.3369 - acc: 0.0485 - val_loss: 15.3640 - val_acc: 0.0468\n",
      "Epoch 3/50\n",
      "392/392 [==============================] - 5s 13ms/step - loss: 15.2546 - acc: 0.0536 - val_loss: 15.3640 - val_acc: 0.0468\n",
      "Epoch 4/50\n",
      "392/392 [==============================] - 5s 13ms/step - loss: 15.6658 - acc: 0.0281 - val_loss: 15.3640 - val_acc: 0.0468\n",
      "\n",
      "F1 Score: 0.03613086770981508\n"
     ]
    }
   ],
   "source": [
    "# K.backend.get_session()\n",
    "\n",
    "model = LeNetRelu.build(input_shape=INPUT_SHAPE, classes=CLASSES)\n",
    "\n",
    "history = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS,\n",
    "        epochs=NB_EPOCH,\n",
    "#         verbose=VERBOSE,\n",
    "        validation_data=validation_generator,\n",
    "#         validation_steps=STEPS,\n",
    "        callbacks = [early_stop]\n",
    ")\n",
    "\n",
    "print(\"\\nF1 Score: {}\".format(f_score_calc(model)))\n",
    "\n",
    "# K.backend.clear_session()\n",
    "del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig('c1_acc.jpg')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.savefig('c1_loss.jpg')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
